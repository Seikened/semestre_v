{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caefa760",
   "metadata": {},
   "source": [
    "# FERNANDO LEON FRANCO | PRACTICA DE TCOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "823bb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from colorstreak import Logger\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c23c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bar(i, cantidad_registros, contexto=\"PROGRESO\"):\n",
    "    porcentaje = (i + 1) / cantidad_registros * 100\n",
    "    # Con emojis\n",
    "    barra = int(50 * (i + 1) / cantidad_registros) * \"üü©\"\n",
    "    espacio = int(50 - len(barra)) * \"‚¨õÔ∏è\"\n",
    "\n",
    "    print(f\"\\r{contexto}: |{barra}{espacio}| {porcentaje:6.2f}%\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5e56de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus, path_truth):\n",
    "\n",
    "    tr_txt = [] # Aqui van los twits\n",
    "    tr_y = [] # Aqui van las etiquetas\n",
    "\n",
    "    with open(path_corpus, 'r', encoding='utf-8') as f_corpus, open(path_truth , 'r', encoding='utf-8') as f_truth:\n",
    "        \n",
    "        for twitt in f_corpus:\n",
    "            tr_txt += [twitt]\n",
    "            \n",
    "        for label in f_truth:\n",
    "            tr_y += [label]\n",
    "    \n",
    "    return tr_txt,tr_y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7b04b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_global = \"data/mex\"\n",
    "path_corpus = path_global + '/mex20_train.txt'\n",
    "path_truth = path_global + '/mex20_train_labels.txt'\n",
    "\n",
    "\n",
    "tr_txt, tr_y = get_texts_from_file(path_corpus,path_truth)\n",
    "\n",
    "\n",
    "\n",
    "# Construir los datos de validaci√≥n\n",
    "path_corpus = path_global + '/mex20_val.txt'\n",
    "path_truth = path_global + '/mex20_val_labels.txt'\n",
    "\n",
    "\n",
    "va_txt, va_y = get_texts_from_file(path_corpus,path_truth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19f41c",
   "metadata": {},
   "source": [
    "# TOKENIZACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d62964e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "corpus_de_palabras = []\n",
    "\n",
    "for doc in tr_txt:\n",
    "    corpus_de_palabras += tokenizer.tokenize(doc)\n",
    "    \n",
    "fdist = nltk.FreqDist(corpus_de_palabras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "087add48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VERSION DEL PROFE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sort_dist(freq_dist):\n",
    "    aux = [(freq_dist[key], key) for key in freq_dist.keys()]\n",
    "    aux.sort(reverse=True)\n",
    "    return aux\n",
    "\n",
    "vocabulario = sort_dist(fdist)\n",
    "\n",
    "vocabulario = vocabulario[:5000] # Shape (5000, 2)\n",
    "\n",
    "\n",
    "# Es redundante pero asegura un orden en diccionario en Python (No importa por que python se indexa)\n",
    "\n",
    "dict_indices = {}\n",
    "\n",
    "contador = 0\n",
    "\n",
    "for peso, palabra in vocabulario:\n",
    "    dict_indices[palabra] = contador\n",
    "    contador += 1\n",
    "    \n",
    "\n",
    "def built_bow_tr_profe_version(tuits, Vocabulario, dict_indices):\n",
    "    \n",
    "    BOW = np.zeros((len(tuits), len(Vocabulario)), dtype=int)\n",
    "\n",
    "    contador = 0\n",
    "    for tr in tuits:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr.lower())) # Tuit Tokenizado\n",
    "        for palabra in fdist_doc:\n",
    "            if palabra in dict_indices:\n",
    "                BOW[contador, dict_indices[palabra]] = fdist_doc[palabra] # FRECUENCIA DE LA PALABRA EN VEZ DE HACERLO BINARIO\n",
    "        contador += 1\n",
    "    return BOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bc3cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0]], shape=(5278, 5000))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolsa_de_palabras_tr = built_bow_tr_profe_version(tr_txt, vocabulario, dict_indices)\n",
    "bolsa_de_palabras_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ac695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semestre-v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
