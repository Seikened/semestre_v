{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da3245f",
   "metadata": {},
   "source": [
    "# FERNANDO LEON FRANCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae49b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from colorstreak import Logger\n",
    "import re\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b42045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bar(i, cantidad_registros, contexto=\"PROGRESO\"):\n",
    "    porcentaje = (i + 1) / cantidad_registros * 100\n",
    "    # Con emojis\n",
    "    barra = int(50 * (i + 1) / cantidad_registros) * \"ğŸŸ©\"\n",
    "    espacio = int(50 - len(barra)) * \"â¬›ï¸\"\n",
    "\n",
    "    print(f\"\\r{contexto}: |{barra}{espacio}| {porcentaje:6.2f}%\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a55da",
   "metadata": {},
   "source": [
    "# MEJORAR LA CARGA DESDE UN CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4e63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] Archivo CSV creado en: \"/Users/ferleon/Github/semestre_v/procesamiento_lenguaje/data/author_profiling/es_test/truth_test.csv\"\u001b[0m\n",
      "\u001b[94m[INFO] Archivo CSV creado en: \"/Users/ferleon/Github/semestre_v/procesamiento_lenguaje/data/author_profiling/es_train/truth_train.csv\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generar_csv(path_lectura, path_guardado):\n",
    "    # Obtener la ruta absoluta del directorio actual\n",
    "    # Leerlo y convertirlo en un DataFrame .csv para manipularlo mejor\n",
    "    with open(path_lectura, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    data = [line.strip().split(\":::\") for line in lines]\n",
    "\n",
    "\n",
    "    df = pl.DataFrame(data, schema=[\"id\", \"genero\", \"pais\"], orient=\"row\")\n",
    "\n",
    "\n",
    "    # Guardar el DataFrame como un archivo .csv\n",
    "    df.write_csv(path_guardado)\n",
    "    return True\n",
    "\n",
    "# ==================== ConfiguraciÃ³n de rutas =====================\n",
    "\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "# ===================== CreaciÃ³n de CSV de datos de prueba =====================\n",
    "ruta_lectura_prueba = os.path.join(base_path, \"data/author_profiling/es_test/truth.txt\")\n",
    "ruta_guardado_prueba = os.path.join(base_path, \"data/author_profiling/es_test/truth_test.csv\")\n",
    "\n",
    "creado = generar_csv(ruta_lectura_prueba, ruta_guardado_prueba)\n",
    "\n",
    "if creado:\n",
    "    Logger.info(f'Archivo CSV creado en: \"{ruta_guardado_prueba}\"')\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ===================== CreaciÃ³n de CSV de datos de entrenamiento ==============\n",
    "ruta_lectura_entrenamiento = os.path.join(base_path, \"data/author_profiling/es_train/truth.txt\")\n",
    "ruta_guardado_entrenamiento = os.path.join(base_path, \"data/author_profiling/es_train/truth_train.csv\")\n",
    "\n",
    "creado_entrenamiento = generar_csv(ruta_lectura_entrenamiento, ruta_guardado_entrenamiento)\n",
    "if creado_entrenamiento:\n",
    "    Logger.info(f'Archivo CSV creado en: \"{ruta_guardado_entrenamiento}\"')\n",
    "# ==============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e521660",
   "metadata": {},
   "source": [
    "# CARGAR LOS INDICES DESDE TRUTH DESDE EL CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e4c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id                              â”† genero â”† pais     â”‚\n",
      "â”‚ ---                             â”† ---    â”† ---      â”‚\n",
      "â”‚ str                             â”† str    â”† str      â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† female â”† colombia â”‚\n",
      "â”‚ 4639c055f34ca1f944d0137a5aeb79â€¦ â”† female â”† colombia â”‚\n",
      "â”‚ 92ffa98bade702b86417b118e8aca3â€¦ â”† female â”† colombia â”‚\n",
      "â”‚ 4560c6567afcccef265f048ed117d0â€¦ â”† female â”† colombia â”‚\n",
      "â”‚ 393866dfaa80d414c9896cf8723932â€¦ â”† female â”† colombia â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "CARGA XML: |ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©| 100.00%\n",
      "\u001b[94m[INFO] Carga de archivos XML completada.\n",
      "\u001b[0m\n",
      "\u001b[92m[DEBUG] Total de tweets crudos cargados: 4200 mostrando 1 registro:\n",
      " id:74bcc9b0882c8440716ff370494aea09\n",
      " pais:colombia\n",
      " genero:female\n",
      " xml_text:\n",
      "<author lang=\"es\">\n",
      "\t<documents>\n",
      "\t\t<document><![CDA...\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def cargar_xml(id_archivo, train=True) -> str:\n",
    "    ruta_base = os.path.join(base_path, \"data/author_profiling/es_test\" if not train else \"data/author_profiling/es_train\")\n",
    "    ruta_archivo = os.path.join(ruta_base, f\"{id_archivo}.xml\")\n",
    "    # Logger.info(f\"ruta archivo: {ruta_archivo}\")\n",
    "    \n",
    "    with open(ruta_archivo, 'r', encoding='utf-8') as file:\n",
    "        xml_text = file.read()\n",
    "\n",
    "    return xml_text\n",
    "\n",
    "# ===================== Cargar CSV de datos  ==================\n",
    " \n",
    "df_indices = pl.read_csv(ruta_guardado_entrenamiento)\n",
    "print(df_indices.head())\n",
    "\n",
    "cantidad_registros = len(df_indices)\n",
    "\n",
    "registros_crudos = [(\"id_user\",\"xml_doc\",\"pais\",\"genero\") for i in range(cantidad_registros)]\n",
    "\n",
    "\n",
    "for i, reg in enumerate(registros_crudos):\n",
    "    id_archivo = df_indices['id'][i]\n",
    "    id_user = id_archivo\n",
    "    pais = df_indices['pais'][i]\n",
    "    genero = df_indices['genero'][i]\n",
    "\n",
    "    xml_text: str = cargar_xml(id_archivo)\n",
    "    registros_crudos[i] = (id_user, xml_text, pais, genero)\n",
    "\n",
    "    print_bar(i, cantidad_registros, contexto=\"CARGA XML\")\n",
    "\n",
    "print()\n",
    "Logger.info(\"Carga de archivos XML completada.\\n\")\n",
    "id_user, xml_text, pais, genero = registros_crudos[0]\n",
    "\n",
    "\n",
    "Logger.debug(f\"Total de tweets crudos cargados: {len(registros_crudos)} mostrando 1 registro:\\n id:{id_user}\\n pais:{pais}\\n genero:{genero}\\n xml_text:\\n{xml_text[:50]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4685f1",
   "metadata": {},
   "source": [
    "# PROCESAMOS LOS TEXTOS XML Y LOS DEJAMOS EN UN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0287180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progreso registros limpiados: |ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©| 100.00%\n",
      "\u001b[94m[INFO] Guardando archivo\u001b[0m\n",
      "\u001b[92m[DEBUG] Total de tweets procesados: 419998 mostrando 5 primeros registros:\n",
      " shape: (5, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id_user                         â”† tweet_crudo                     â”† pais     â”† genero â”† idioma  â”‚\n",
      "â”‚ ---                             â”† ---                             â”† ---      â”† ---    â”† ---     â”‚\n",
      "â”‚ str                             â”† str                             â”† str      â”† str    â”† str     â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† Tiene que valer la pena que esâ€¦ â”† colombia â”† female â”† EspaÃ±ol â”‚\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† Tintas chinas, si ven Ã©sto, esâ€¦ â”† colombia â”† female â”† EspaÃ±ol â”‚\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† \"Maestro no le abriÃ³!\" -Ay quÃ©â€¦ â”† colombia â”† female â”† EspaÃ±ol â”‚\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† Lo bueno de no estar enamoradoâ€¦ â”† colombia â”† female â”† EspaÃ±ol â”‚\n",
      "â”‚ 74bcc9b0882c8440716ff370494aeaâ€¦ â”† RecordarÃ© este dÃ­a como el dÃ­aâ€¦ â”† colombia â”† female â”† EspaÃ±ol â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "diccionario_idioma = {\n",
    "    'es': 'EspaÃ±ol', \n",
    "    'en': 'InglÃ©s', \n",
    "    'fr': 'FrancÃ©s', \n",
    "    'de': 'AlemÃ¡n', \n",
    "    'it': 'Italiano', \n",
    "    'nl': 'NeerlandÃ©s'\n",
    "}\n",
    "\n",
    "def limpiar_xml(texto_xml:str):\n",
    "    soup = BeautifulSoup(texto_xml, 'lxml-xml')   \n",
    "    lang = str(soup.author.get('lang'))\n",
    "    idioma = diccionario_idioma[lang] if lang in diccionario_idioma else lang\n",
    "    \n",
    "    documentos = soup.find_all('document') # Obtenemos todsa las etiquetas <document>\n",
    "    tweets = [doc.get_text(separator=\" \", strip=True) for doc in documentos] # Extraemos el texto de cada documento\n",
    "    \n",
    "    return tweets, idioma\n",
    "\n",
    "\n",
    "\n",
    "# ===================== Procesamiento de limpieza del XML =====================\n",
    "cantidad_registros = len(registros_crudos)\n",
    "\n",
    "registros_procesados = []\n",
    "\n",
    "for i, (id_user, doc_crudo, pais, genero) in enumerate(registros_crudos):\n",
    "    lista_tweets_por_usuario, idioma = limpiar_xml(doc_crudo)\n",
    "    \n",
    "    for tweet in lista_tweets_por_usuario:\n",
    "        registros_procesados.append({\n",
    "            \"id_user\": id_user,\n",
    "            \"tweet_crudo\": tweet,\n",
    "            \"pais\": pais,\n",
    "            \"genero\": genero,\n",
    "            \"idioma\": idioma\n",
    "        })\n",
    "    print_bar(i, cantidad_registros, contexto=\"Progreso registros limpiados\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ===================== Creamos dataset persistente =====================\n",
    "\n",
    "df_registros = pl.DataFrame(registros_procesados)\n",
    "df_registros.write_parquet(\"data/author_profiling/registros_procesados.parquet\")\n",
    "Logger.info(\"Guardando archivo\")\n",
    "\n",
    "lf_registros = df_registros.lazy()\n",
    "\n",
    "# ===================== Muestra =====================\n",
    "\n",
    "\n",
    "muestra = lf_registros.limit(5).collect()\n",
    "Logger.debug(f\"Total de tweets procesados: {len(registros_procesados)} mostrando 5 primeros registros:\\n {muestra}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45b49c",
   "metadata": {},
   "source": [
    "\n",
    "# Capa de dataclass de utilidd para normalizaciÃ³n y limpieza de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15eed5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import unicodedata\n",
    "# ===================== ConfiguraciÃ³n de Limpieza de tweets =====================\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ConfigLimpieza:\n",
    "    normalizar_unicode: bool = True\n",
    "    a_minusculas: bool = True\n",
    "    quitar_urls: bool = True\n",
    "    quitar_menciones: bool = True\n",
    "    quitar_hashtags: bool = False \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Tweet:\n",
    "    URL = re.compile(r'https?://\\S+', re.I)\n",
    "    MENCION = re.compile(r'@\\w+')\n",
    "    HASHTAG = re.compile(r'#\\w+')\n",
    "    ESPACIO = re.compile(r'\\s+')\n",
    "    TT = TweetTokenizer()\n",
    "\n",
    "    @staticmethod\n",
    "    def limpiar(texto: str) -> str:\n",
    "        cfg = ConfigLimpieza()\n",
    "        if cfg.normalizar_unicode:\n",
    "            texto = unicodedata.normalize(\"NFKC\", texto)\n",
    "        if cfg.a_minusculas:\n",
    "            texto = texto.lower()\n",
    "        if cfg.quitar_urls:\n",
    "            texto = Tweet.URL.sub(\" \", texto)\n",
    "        if cfg.quitar_menciones:\n",
    "            texto = Tweet.MENCION.sub(\" \", texto)\n",
    "        if cfg.quitar_hashtags:\n",
    "            texto = Tweet.HASHTAG.sub(\" \", texto)\n",
    "\n",
    "        texto_limpio = Tweet.ESPACIO.sub(\" \", texto).strip()\n",
    "        return texto_limpio\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizar(texto: str) -> list[str]:\n",
    "        return [t for t in Tweet.TT.tokenize(texto)]\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eca741",
   "metadata": {},
   "source": [
    "# PIPELINE DE LIMPIEZA Y/O TOKENIZACIÃ“N DE TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3714c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] PIPELINE: LIMPIEZA/ TOKENIZACIÃ“N\u001b[0m\n",
      "\u001b[92m[DEBUG] Mostrando registros del lazyframe limpio:\n",
      " shape: (2, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id_user              â”† tweet_crudo          â”† pais     â”† genero â”† idioma  â”† texto_limpio         â”‚\n",
      "â”‚ ---                  â”† ---                  â”† ---      â”† ---    â”† ---     â”† ---                  â”‚\n",
      "â”‚ str                  â”† str                  â”† str      â”† str    â”† str     â”† str                  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 74bcc9b0882c8440716f â”† Tiene que valer la   â”† colombia â”† female â”† EspaÃ±ol â”† tiene que valer la   â”‚\n",
      "â”‚ f370494aeaâ€¦          â”† pena que esâ€¦         â”†          â”†        â”†         â”† pena que esâ€¦         â”‚\n",
      "â”‚ 74bcc9b0882c8440716f â”† Tintas chinas, si    â”† colombia â”† female â”† EspaÃ±ol â”† tintas chinas, si    â”‚\n",
      "â”‚ f370494aeaâ€¦          â”† ven Ã©sto, esâ€¦        â”†          â”†        â”†         â”† ven Ã©sto, esâ€¦        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "\u001b[94m[INFO] Primer tweet limpio: tiene que valer la pena que estÃ© despierta a esta hora #hoylosgrammycon40\u001b[0m\n",
      "\u001b[92m[DEBUG] Mostrando registros del lazyframe tokenizado:\n",
      " shape: (2, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id_user         â”† tweet_crudo    â”† pais     â”† genero â”† idioma  â”† texto_limpio   â”† tweets_tokeniz â”‚\n",
      "â”‚ ---             â”† ---            â”† ---      â”† ---    â”† ---     â”† ---            â”† ados           â”‚\n",
      "â”‚ str             â”† str            â”† str      â”† str    â”† str     â”† str            â”† ---            â”‚\n",
      "â”‚                 â”†                â”†          â”†        â”†         â”†                â”† list[str]      â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† [\"tiene\",      â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”† \"que\", â€¦       â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”† \"#hoylosgraâ€¦   â”‚\n",
      "â”‚ 74bcc9b0882c844 â”† Tintas chinas, â”† colombia â”† female â”† EspaÃ±ol â”† tintas chinas, â”† [\"tintas\",     â”‚\n",
      "â”‚ 0716ff370494aea â”† si ven Ã©sto,   â”†          â”†        â”†         â”† si ven Ã©sto,   â”† \"chinas\", â€¦    â”‚\n",
      "â”‚ â€¦               â”† esâ€¦            â”†          â”†        â”†         â”† esâ€¦            â”† \"xoxo\"]        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "\u001b[94m[INFO] Primer tweet tokenizado: shape: (12,)\n",
      "Series: '' [str]\n",
      "[\n",
      "\t\"tiene\"\n",
      "\t\"que\"\n",
      "\t\"valer\"\n",
      "\t\"la\"\n",
      "\t\"pena\"\n",
      "\tâ€¦\n",
      "\t\"despierta\"\n",
      "\t\"a\"\n",
      "\t\"esta\"\n",
      "\t\"hora\"\n",
      "\t\"#hoylosgrammycon40\"\n",
      "]\u001b[0m\n",
      "\u001b[94m[INFO] Token: tiene\u001b[0m\n",
      "\u001b[94m[INFO] Token: que\u001b[0m\n",
      "\u001b[94m[INFO] Token: valer\u001b[0m\n",
      "\u001b[94m[INFO] Token: la\u001b[0m\n",
      "\u001b[94m[INFO] Token: pena\u001b[0m\n",
      "\u001b[94m[INFO] Token: que\u001b[0m\n",
      "\u001b[94m[INFO] Token: estÃ©\u001b[0m\n",
      "\u001b[94m[INFO] Token: despierta\u001b[0m\n",
      "\u001b[94m[INFO] Token: a\u001b[0m\n",
      "\u001b[94m[INFO] Token: esta\u001b[0m\n",
      "\u001b[94m[INFO] Token: hora\u001b[0m\n",
      "\u001b[94m[INFO] Token: #hoylosgrammycon40\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===================== TRANSFORMACIONES EN PIPELINE =====================\n",
    "\"\"\"\n",
    "Recordemos que los pipelines de polars si es un lazyframe no se ejecutan hasta que se les pida con .collect() (DocoumentaciÃ³n)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lf_registros_crudos = lf_registros\n",
    "\n",
    "\n",
    "Logger.info(\"PIPELINE: LIMPIEZA/ TOKENIZACIÃ“N\")\n",
    "lf_limpio = (\n",
    "    lf_registros_crudos.with_columns(\n",
    "        pl.col(\"tweet_crudo\")\n",
    "          .map_elements(Tweet.limpiar)\n",
    "          .alias(\"texto_limpio\")\n",
    "    )\n",
    ")\n",
    "\n",
    "Logger.debug(f\"Mostrando registros del lazyframe limpio:\\n {lf_limpio.limit(2).collect()}\")\n",
    "\n",
    "primer_tweet_limpio = (\n",
    "    lf_limpio\n",
    "    .select('texto_limpio')\n",
    "    .limit(1)\n",
    "    .collect()\n",
    "    .to_series()\n",
    "    .to_list()[0]\n",
    ")\n",
    "\n",
    "Logger.info(f\"Primer tweet limpio: {primer_tweet_limpio}\")\n",
    "        \n",
    "lf_tokens = (\n",
    "    lf_limpio.with_columns(\n",
    "        pl.col(\"texto_limpio\")\n",
    "          .map_elements(\n",
    "              Tweet.tokenizar, \n",
    "              return_dtype=pl.List(pl.Utf8), \n",
    "              skip_nulls=True\n",
    "            )\n",
    "          .alias(\"tweets_tokenizados\")\n",
    "    )\n",
    ")\n",
    "\n",
    "Logger.debug(f\"Mostrando registros del lazyframe tokenizado:\\n {lf_tokens.limit(2).collect()}\")\n",
    "\n",
    "\n",
    "# ======================== Metodo para extraer el primer tweet tokenizado con polars =====================\n",
    "primer_tweet_tokenizado = (\n",
    "    lf_tokens\n",
    "    .select(\"tweets_tokenizados\") # Seleccionamos la columna que nos interesa\n",
    "    .limit(1) \n",
    "    .collect()\n",
    "    .item()  # Sirve para extraer el valor cuando el DataFrame es 1x1\n",
    ")\n",
    "# ========================================================================================================\n",
    "\n",
    "Logger.info(f\"Primer tweet tokenizado: {primer_tweet_tokenizado}\")\n",
    "\n",
    "for token in primer_tweet_tokenizado:\n",
    "    Logger.info(f\"Token: {token}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a514f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[INFO] CONSTRUCCIÃ“N DE VOCABULARIO GLOBAL\u001b[0m\n",
      "\u001b[92m[DEBUG] Mostrando registros del lazyframe explotado:\n",
      " shape: (5, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ id_user         â”† tweet_crudo    â”† pais     â”† genero â”† idioma  â”† texto_limpio   â”† tweets_tokeniz â”‚\n",
      "â”‚ ---             â”† ---            â”† ---      â”† ---    â”† ---     â”† ---            â”† ados           â”‚\n",
      "â”‚ str             â”† str            â”† str      â”† str    â”† str     â”† str            â”† ---            â”‚\n",
      "â”‚                 â”†                â”†          â”†        â”†         â”†                â”† str            â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† tiene          â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”†                â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”†                â”‚\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† que            â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”†                â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”†                â”‚\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† valer          â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”†                â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”†                â”‚\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† la             â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”†                â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”†                â”‚\n",
      "â”‚ 74bcc9b0882c844 â”† Tiene que      â”† colombia â”† female â”† EspaÃ±ol â”† tiene que      â”† pena           â”‚\n",
      "â”‚ 0716ff370494aea â”† valer la pena  â”†          â”†        â”†         â”† valer la pena  â”†                â”‚\n",
      "â”‚ â€¦               â”† que esâ€¦        â”†          â”†        â”†         â”† que esâ€¦        â”†                â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "\u001b[92m[DEBUG] Mostrando registros del lazyframe con conteos:\n",
      " shape: (5, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ token â”† len    â”‚\n",
      "â”‚ ---   â”† ---    â”‚\n",
      "â”‚ str   â”† u32    â”‚\n",
      "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ de    â”† 215391 â”‚\n",
      "â”‚ ,     â”† 161864 â”‚\n",
      "â”‚ .     â”† 156802 â”‚\n",
      "â”‚ que   â”† 149950 â”‚\n",
      "â”‚ la    â”† 135889 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n",
      "\u001b[94m[INFO] Total de tokens Ãºnicos en vocabulario: 205231. Mostrando 5 primeros:\n",
      " shape: (5, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ token_id â”† token â”† len    â”‚\n",
      "â”‚ ---      â”† ---   â”† ---    â”‚\n",
      "â”‚ u32      â”† str   â”† u32    â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0        â”† de    â”† 215391 â”‚\n",
      "â”‚ 1        â”† ,     â”† 161864 â”‚\n",
      "â”‚ 2        â”† .     â”† 156802 â”‚\n",
      "â”‚ 3        â”† que   â”† 149950 â”‚\n",
      "â”‚ 4        â”† la    â”† 135889 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===================== VOCABULARIO GLOBAL =====================\n",
    "\n",
    "Logger.info(\"CONSTRUCCIÃ“N DE VOCABULARIO GLOBAL\")\n",
    "\n",
    "# 1) Aplanamos la lista de tokens a filas\n",
    "lf_explotado = lf_tokens.explode(\"tweets_tokenizados\")\n",
    "\n",
    "Logger.debug(f\"Mostrando registros del lazyframe explotado:\\n {lf_explotado.limit(5).collect()}\")\n",
    "\n",
    "# 2) Conteo de frecuencia global de cada token\n",
    "lf_conteos = (\n",
    "    lf_explotado\n",
    "    .group_by(pl.col(\"tweets_tokenizados\").alias(\"token\"))\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)  # o .sort(\"token\") si quieres orden alfabÃ©tico\n",
    "\n",
    ")\n",
    "\n",
    "Logger.debug(f\"Mostrando registros del lazyframe con conteos:\\n {lf_conteos.limit(5).collect()}\")\n",
    "\n",
    "# 3) Asignamos un ID de token estable (0..V-1) y persistimos\n",
    "df_vocab = (\n",
    "    lf_conteos\n",
    "    .with_row_index(name=\"token_id\", offset=0)  # reemplaza with_row_count\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "Logger.info(f\"Total de tokens Ãºnicos en vocabulario: {len(df_vocab)}. Mostrando 5 primeros:\\n {df_vocab.head()}\")\n",
    "df_vocab.write_parquet(\"data/author_profiling/vocabulario.parquet\")\n",
    "# schema: token_id: u32, token: Utf8, len: u32  (len = frecuencia global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad80ef7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semestre-v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
