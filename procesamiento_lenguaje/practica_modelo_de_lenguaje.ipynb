{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4261fdc",
   "metadata": {},
   "source": [
    "# FERNANDO LEON FRANCO | PRACTICA MODELO DE LENGUAJE PROBABILISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709c1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3464b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus, path_truth):\n",
    "\n",
    "    tr_txt = [] # Aqui van los twits\n",
    "    tr_y = [] # Aqui van las etiquetas\n",
    "\n",
    "    with open(path_corpus, 'r', encoding='utf-8') as f_corpus, open(path_truth , 'r', encoding='utf-8') as f_truth:\n",
    "        \n",
    "        for twitt in f_corpus:\n",
    "            tr_txt += [twitt]\n",
    "            \n",
    "        for label in f_truth:\n",
    "            tr_y += [label]\n",
    "    \n",
    "    return tr_txt,tr_y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf67095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_global = \"/Users/ferleon/Github/semestre_v/procesamiento_lenguaje/data/mex\"\n",
    "path_corpus = path_global + '/mex20_train.txt'\n",
    "path_truth = path_global + '/mex20_train_labels.txt'\n",
    "\n",
    "\n",
    "tr_txt, tr_y = get_texts_from_file(path_corpus,path_truth)\n",
    "\n",
    "\n",
    "\n",
    "# Construir los datos de validación\n",
    "path_corpus = path_global + '/mex20_val.txt'\n",
    "path_truth = path_global + '/mex20_val_labels.txt'\n",
    "\n",
    "\n",
    "va_txt, va_y = get_texts_from_file(path_corpus,path_truth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ac2a3",
   "metadata": {},
   "source": [
    "# PARTE 1: Procesamiento y tratamiento de los datos para un modelo de lenguaje probabilista\n",
    "- Necesitamos contar las ocurrencias de trigramas o de bigramas en el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf50168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramData:\n",
    "    MODE = \"TRIGRAM\"\n",
    "    def __init__(self, vocab_max, tokenizer):\n",
    "        self.vocab_max = vocab_max\n",
    "        self.tokenizer = tokenizer\n",
    "        self.final_vocab = set()\n",
    "        self.SOS = \"<s>\"\n",
    "        self.EOS = \"</s>\"\n",
    "        self.UNK = \"<unk>\"\n",
    "        \n",
    "    def fit(self, raw_text): # En row_text recibiré los tweets\n",
    "        freq_dist = nltk.FreqDist()\n",
    "        tokenized_corpus = []\n",
    "        \n",
    "        for txt in raw_text:\n",
    "            tokens = self.tokenizer.tokenize(txt.lower())\n",
    "            tokenized_corpus.append(tokens) # recordar que esta es una lista de listas de tweets tokenizados\n",
    "            for w in tokens:\n",
    "                freq_dist[w] += 1\n",
    "                \n",
    "        self.final_vocab = { token for token, _ in freq_dist.most_common(self.vocab_max) }\n",
    "        self.final_vocab.update([self.SOS, self.EOS, self.UNK])\n",
    "        \n",
    "        transform_corpus = []\n",
    "        for tokens in tokenized_corpus:\n",
    "            transform_corpus.append(self.transform(tokens)) # tokens es un tweet tokenizado\n",
    "        \n",
    "        \n",
    "        return transform_corpus\n",
    "    \n",
    "    \n",
    "    def mask_out_of_vocab(self, word):\n",
    "        if word in self.final_vocab:\n",
    "            return word\n",
    "        else:\n",
    "            return self.UNK\n",
    "\n",
    "    def add_sos_eos(self, tokenized_text):\n",
    "        \n",
    "        if self.MODE == \"BIGRAM\":\n",
    "            return [self.SOS] + tokenized_text + [self.EOS]\n",
    "        elif self.MODE == \"TRIGRAM\":\n",
    "            return [self.SOS, self.SOS] + tokenized_text + [self.EOS]\n",
    "\n",
    "    def transform(self, tokenized_text):\n",
    "        transformed = [] # Tokens transformados\n",
    "        for w in tokenized_text:\n",
    "            transformed.append(self.mask_out_of_vocab(w)) # Mask  Out of Vocabulary Word\n",
    "        transformed = self.add_sos_eos(transformed)\n",
    "\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057aaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_PALABRAS = 10_000\n",
    "tokenizador = TweetTokenizer()\n",
    "\n",
    "trigram_data = TrigramData(vocab_max=TOP_PALABRAS, tokenizer=tokenizador)\n",
    "\n",
    "transformed_corpus = trigram_data.fit(tr_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d976b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario final: 10,003\n"
     ]
    }
   ],
   "source": [
    "final_vocab = trigram_data.final_vocab\n",
    "print(f\"Tamaño del vocabulario final: {len(final_vocab):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77761c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dejé\n",
      "lárgate\n",
      "loros\n",
      "preocupada\n",
      "cambielos\n",
      "pasará\n",
      "estupida\n",
      "viéndolo\n",
      "pendejolandia\n",
      "malas\n",
      "clave\n",
      "blanco\n",
      "juegaso\n",
      "iglesia\n",
      "rogelio\n",
      "podamos\n",
      "goloso\n",
      "comparte\n",
      "hablas\n",
      "suena\n"
     ]
    }
   ],
   "source": [
    "for palabra in list(final_vocab)[:20]:\n",
    "    print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "076364d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 20 palabras del vocabulario final:\n",
      " 1. !\n",
      " 2. \"\n",
      " 3. #\n",
      " 4. #140caracteres\n",
      " 5. #19s\n",
      " 6. #280caracteres\n",
      " 7. #aba\n",
      " 8. #aborto\n",
      " 9. #acropolispuebla\n",
      "10. #addi\n",
      "11. #adn\n",
      "12. #agsmx\n",
      "13. #aguascalientes\n",
      "14. #aguilas\n",
      "15. #ahscult\n",
      "16. #alaorden\n",
      "17. #alerta\n",
      "18. #alvlavida\n",
      "19. #amedroauditor\n",
      "20. #amigos\n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras 20 palabras del vocabulario final:\")\n",
    "for idx, palabra in enumerate(sorted(final_vocab)):\n",
    "    if idx < 20:\n",
    "        print(f\"{idx+1:2d}. {palabra}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0fae9",
   "metadata": {},
   "source": [
    "# BUILDING A TRIGRAM LANGUAGE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd26131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramLanguageModel:\n",
    "    \"\"\" Modelo interpolado  unigramas + bigramas + trigramas \"\"\"\n",
    "    def __init__(self, lambda_1 = 0.59, lambda_2 = 0.40, lambda_3 = 0.01, vocab=None):\n",
    "        # Las lambdas deben sumar 1 y son los pesos de cada modelo\n",
    "        self.lambda_1 = lambda_1 # Trigramas\n",
    "        self.lambda_2 = lambda_2 # Bigramas\n",
    "        self.lambda_3 = lambda_3 # Unigramas\n",
    "        \n",
    "        # Contadores\n",
    "        self.unigram_counts = {} # Los unigramas con las palabras solitas\n",
    "        self.bigram_counts = {}  # Los bigramas subsecuencias de tamaño 2\n",
    "        self.trigram_counts = {} # Los trigramas subsecuencias de tamaño 3\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab) if vocab is not None else 0\n",
    "\n",
    "\n",
    "    def train(self, transformed_corpus):\n",
    "        for tokens in transformed_corpus: # primero recorro tweet por tweet\n",
    "            for i, word in enumerate(tokens): # Luego para cada tweet le reccorro sus palabras\n",
    "                \n",
    "                # Unigramas\n",
    "                self.unigram_counts[word] = self.unigram_counts.get(word, 0) + 1\n",
    "                \n",
    "                # Bigramas\n",
    "                if i > 0: # Solo si ya vi un palabra antes, puedo formar un bigrama\n",
    "                    bigrama = (tokens[i-1], word)\n",
    "                    self.bigram_counts[bigrama] = self.bigram_counts.get(bigrama, 0) + 1\n",
    "                \n",
    "                # Trigramas\n",
    "                if i > 1: # Solo si ya vi dos palabras antes, puedo formar un trigrama\n",
    "                    trigrama = (tokens[i-2], tokens[i-1], word)\n",
    "                    self.trigram_counts[trigrama] = self.trigram_counts.get(trigrama, 0) + 1\n",
    "            \n",
    "            self.total_tokens = sum(self.unigram_counts.values())\n",
    "    \n",
    "    \n",
    "    def mask_out_of_vocab(self, word):\n",
    "        return \"<unk>\" if word not in self.vocab else word\n",
    "    \n",
    "    \n",
    "    def unigram_probability(self, word):\n",
    "        numerador = self.unigram_counts.get(self.mask_out_of_vocab(word), 0) + 1\n",
    "        denominador = self.total_tokens + self.vocab_size\n",
    "        return numerador / denominador\n",
    "                    \n",
    "                    \n",
    "    def bigram_probability(self, word_prev, word): # Esta función calcula P(word | word_prev)\n",
    "        w_prev = self.mask_out_of_vocab(word_prev)\n",
    "        w = self.mask_out_of_vocab(word)\n",
    "        bigrama = (w_prev, w) # P(w | w_prev)\n",
    "        \n",
    "        numerador = self.bigram_counts.get(bigrama, 0) + 1\n",
    "        denominador = self.unigram_counts.get(w_prev, 0) + self.vocab_size\n",
    "        return  numerador / denominador\n",
    "    \n",
    "    \n",
    "    def trigram_probability(self, word_prev2, word_prev1, word): # Esta función calcula P(word | word_prev2, word_prev1)\n",
    "        w_prev2 = self.mask_out_of_vocab(word_prev2)\n",
    "        w_prev1 = self.mask_out_of_vocab(word_prev1)\n",
    "        w = self.mask_out_of_vocab(word)\n",
    "        \n",
    "        trigrama = (w_prev2, w_prev1, w)\n",
    "        bigrama = (w_prev2, w_prev1)\n",
    "        numerador = self.trigram_counts.get(trigrama, 0) + 1\n",
    "        denominador = self.bigram_counts.get(bigrama, 0) + self.vocab_size\n",
    "        return  numerador / denominador\n",
    "        \n",
    "    def probability_of_word(self, word_prev2, word_prev1, word):\n",
    "        p1 = self.trigram_probability(word_prev2, word_prev1, word)\n",
    "        p2 = self.bigram_probability(word_prev1, word)\n",
    "        p3 = self.unigram_probability(word)\n",
    "        \n",
    "        return (self.lambda_1 * p1) + (self.lambda_2 * p2) + (self.lambda_3 * p3)\n",
    "\n",
    "\n",
    "    def top_next_words(self, w_prev2, w_prev, top_k=5):\n",
    "        candidates = []\n",
    "        for cand in self.vocab:\n",
    "            p_w = self.probability_of_word(w_prev2, w_prev, cand)\n",
    "            candidates.append((cand, p_w))\n",
    "        # Ordena de mayor a menor probabilidad\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return candidates[:top_k]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def check_probs(self):\n",
    "        print(sum(self.unigram_probability(w) for w in self.vocab)) # Type: ignore\n",
    "        print(sum(self.bigram_probability(\"gato\", w) for w in self.vocab)) # Type: ignore\n",
    "        print(sum(self.trigram_probability(\"hola\", \"como\", w) for w in self.vocab)) # Type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09fff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vocab = trigram_data.final_vocab\n",
    "\n",
    "trigram_lm = TrigramLanguageModel(vocab=final_vocab)\n",
    "trigram_lm.train(transformed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5a32f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "trigram_lm.check_probs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b618b",
   "metadata": {},
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b642ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(mundo | <s>, hola) = 0.00010335132933804556\n"
     ]
    }
   ],
   "source": [
    "word_prev2, word_prev1, word = \"<s>\", \"hola\", \"mundo\"\n",
    "p_w = trigram_lm.probability_of_word(word_prev2, word_prev1, word)\n",
    "print(f\"P({word} | {word_prev2}, {word_prev1}) = {p_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ed6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(a | <s>, saludos) = 0.0002778290833875056\n"
     ]
    }
   ],
   "source": [
    "word_prev2, word_prev1, word = \"<s>\", \"saludos\", \"a\"\n",
    "p_w = trigram_lm.probability_of_word(word_prev2, word_prev1, word)\n",
    "print(f\"P({word} | {word_prev2}, {word_prev1}) = {p_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f19aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(tu | hijo, de) = 0.0034786898082040775\n"
     ]
    }
   ],
   "source": [
    "word_prev2, word_prev1, word = \"hijo\", \"de\", \"tu\"\n",
    "p_w = trigram_lm.probability_of_word(word_prev2, word_prev1, word)\n",
    "print(f\"P({word} | {word_prev2}, {word_prev1}) = {p_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de5468f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(la | vete, a) = 0.011153217757174417\n"
     ]
    }
   ],
   "source": [
    "word_prev2, word_prev1, word = \"vete\", \"a\", \"la\"\n",
    "p_w = trigram_lm.probability_of_word(word_prev2, word_prev1, word)\n",
    "print(f\"P({word} | {word_prev2}, {word_prev1}) = {p_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6dc6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(la | hijo, de) = 0.009244873899638673\n",
      "P(<unk> | hijo, de) = 0.005531514118896191\n",
      "P(tu | hijo, de) = 0.0034786898082040775\n",
      "P(su | hijo, de) = 0.0026121131631923304\n",
      "P(mi | hijo, de) = 0.0025834426767438\n"
     ]
    }
   ],
   "source": [
    "top_5 = trigram_lm.top_next_words(\"hijo\", \"de\", top_k=5)\n",
    "for w, p in top_5:\n",
    "    print(f\"P({w} | hijo, de) = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed5d4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(<s> | hola, mundo) = 0.0009548905419916221\n",
      "P(. | hola, mundo) = 0.0007077447034876222\n",
      "P(</s> | hola, mundo) = 0.0006859567869160297\n",
      "P(, | hola, mundo) = 0.0005422899688591583\n",
      "P(de | hola, mundo) = 0.00042929561320088607\n"
     ]
    }
   ],
   "source": [
    "top_5 = trigram_lm.top_next_words(\"hola\", \"mundo\", top_k=5)\n",
    "for w, p in top_5:\n",
    "    print(f\"P({w} | hola, mundo) = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fadcfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(<s> | saludos, desde) = 0.0009548787514258432\n",
      "P(que | saludos, desde) = 0.0007886220919455008\n",
      "P(el | saludos, desde) = 0.0006111244424612674\n",
      "P(</s> | saludos, desde) = 0.000526851827413192\n",
      "P(la | saludos, desde) = 0.00044192585759427003\n"
     ]
    }
   ],
   "source": [
    "top_5 = trigram_lm.top_next_words(\"saludos\", \"desde\", top_k=5)\n",
    "for w, p in top_5:\n",
    "    print(f\"P({w} | saludos, desde) = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11951538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(la | partido, de) = 0.00906949641563996\n",
      "P(<unk> | partido, de) = 0.005473304741341722\n",
      "P(mi | partido, de) = 0.002583817352411454\n",
      "P(los | partido, de) = 0.002471707927558721\n",
      "P(que | partido, de) = 0.0023270595921347985\n"
     ]
    }
   ],
   "source": [
    "top_5 = trigram_lm.top_next_words(\"partido\", \"de\", top_k=5)\n",
    "for w, p in top_5:\n",
    "    print(f\"P({w} | partido, de) = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50bd01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(<s> | como, estas) = 0.0009549202710826276\n",
      "P(</s> | como, estas) = 0.0006256786737036542\n",
      "P(<unk> | como, estas) = 0.00035164397556725974\n",
      "P(que | como, estas) = 0.00035115739702537346\n",
      "P(de | como, estas) = 0.00034977875782336225\n"
     ]
    }
   ],
   "source": [
    "top_5 = trigram_lm.top_next_words(\"como\", \"estas\", top_k=5)\n",
    "for w, p in top_5:\n",
    "    print(f\"P({w} | como, estas) = {p}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semestre-v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
